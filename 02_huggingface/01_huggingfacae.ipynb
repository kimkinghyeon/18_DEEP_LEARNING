{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_Hugging Face\n",
    "---\n",
    "## 01_01 Hugging Face란?\n",
    "* 코드로 구현되어 있는 모델을 모아놓은 곳으로 AI의 github라 불린다.\n",
    "* 허깅페이스는 최신 AI 기술을 더 간편하게 활용 할 수 있또록 제공되는 플랫폼이며, 핵심기술은 Transformers 라이브러리이다.\n",
    "\n",
    "### 01_01_01 Hugging Face 장점\n",
    "* 모델을 처음부터 개발하고 훈련할 필요가 없다.\n",
    "* 사용 편의성 (간단하고 사용자 친화적인 인터페이스가 제공되어 쉽게 이용가능)\n",
    "* 지속적으로 발전 중 (AI의 최신기술을 공유받고 쉽게 접근 가능)\n",
    "\n",
    "\n",
    "## 01_01 Transformers 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01_01_01 자연어처리\n",
    "* 컴퓨터가 인간의 언어를 이해, 생성, 조작 할 수 있도록 해주는 인공지능의 한 분야\n",
    "\n",
    "**자연어 처리의 주요 단계**\n",
    "\n",
    "* 토큰화: 텍스트를 의미 있는 단위(토큰)로 나누는 과정  \n",
    "    예시: \"나는 학교에 간다\" -> [\"나는\", \"학교에\", \"간다\"]<br>\n",
    "\n",
    "* 단어 집합 생성: 텍스트에서 고유한 단어들을 모아 사전을 만드는 과정  \n",
    "    예시: [\"나는\", \"학교에\", \"간다\"] -> {\"나는\", \"학교에\", \"간다\"}<br>\n",
    "\n",
    "* 정수 인코딩: 단어를 고유한 정수로 변환하여 컴퓨터가 처리할 수 있게 하는 과정  \n",
    "    예시: {\"나는\": 1, \"학교에\": 2, \"간다\": 3} -> [1, 2, 3]<br>\n",
    "\n",
    "* 패딩: 서로 다른 길이의 시퀀스를 동일한 길이로 맞추는 과정  \n",
    "    예시: [1, 2, 3] -> [1, 2, 3, 0, 0] (길이 5로 패딩)<br>\n",
    "\n",
    "* 벡터화: 텍스트 데이터를 숫자 벡터로 변환하여 기계학습 모델에 입력할 수 있게 하는 과정  \n",
    "    예시: \"나는\" -> [0.1, 0.2, 0.3, ..., 0.9] (100차원 벡터)  \n",
    "\n",
    "<br><br>\n",
    "\n",
    "**형태소 토큰화**  \n",
    "<br>\n",
    "원시문 예시 :  \n",
    "\"길을 가다가 고양이를 봤어. 고양이에게 츄르를 주려했는데 고양이가 도망가버렸어\"  \n",
    "\n",
    "토큰화 예시 :  \n",
    "[\"길을\", \"가다가\", \"고양이를\", \"봤어\", \".\", \"고양이에게\", \"츄르를\", \"주려했는데\", \"고양이가\", \"도망가버렸어\"]  \n",
    "\n",
    "똑같은 고양이가 총 3번 등장한다, 이때 \"를\", \"에게\", \"가\" 가 붙어있어 기계는 각기 다른 단어로 인식 할 수 있다.  \n",
    "따라서 한국에서는 보편적으로 '형태소 분석기'로 토큰화를 진행한다.  \n",
    "\n",
    "형태소 토큰화 예시 : \n",
    "[\"길\", \"을\", \"가다가\", \"고양이\", \"를\", \"보\", \"았\", \"어\", \".\", \"고양이\", \"에게\", \"츄르\", \"를\", \"주\", \"려\", \"하\", \"았\", \"는데\", \"고양이\", \"가\", \"도망가\", \"버리\", \"었\", \"어\"]  \n",
    "\n",
    "이렇게 형태소 단위로 분리하면 \"고양이\"라는 단어가 일관되게 인식되며, 조사나 어미는 별도로 분리된다.  \n",
    "이를 통해 기계가 더 정확하게 단어의 의미와 문법적 기능을 파악할 수 있다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자연어 처리 발전 과정\n",
    "\n",
    "**카운트 기반 단어 표현**\n",
    "* 단어 표현 중 하나로, 단어의 빈도수를 기반으로 단어의 의미를 표현하는 방법\n",
    "* DTM(Document Term Matrix) : 문서 내 단어의 빈도수를 기반으로 문서를 표현하는 방법\n",
    "* TF-IDF : 단어의 중요도를 고려하여 문서를 표현하는 방법 <br>\n",
    "\n",
    "Bag of Words(단어주머니)\n",
    "* 문서 내 단어의 출현 여부를 기반으로 문서를 표현하는 방법\n",
    "* 단어의 출현 빈도로만 나타내기 때문에 단어의 순서는 고려하지 않는다.\n",
    "<br> => 문맥 파악이 불가능 (강아지가 놀고 있다 와 놀고 있는 강아지를 구별 못함)\n",
    "\n",
    "**단어임베딩(통계기반의 언어모델)**\n",
    "* 대표적인 알고리즘 : Word2vec, GloVe\n",
    "* 단어를 벡터로 표현하는 방법\n",
    "* 단어의 의미를 벡터로 표현하여 문맥을 고려할 수 있도록 해준다.\n",
    "<br> => 하지만 다의어 같은 (문맥에따라 다양한의미를 기지는걸 구별하지 못함)\n",
    "\n",
    "**딥러닝 기반 언어 모델**\n",
    "\n",
    "**시퀀스 모델**\n",
    "* 시퀀스란?\n",
    "<br>시퀀스는 순서가 있는 데이터의 집합을 의미한다.\n",
    "<br>자연어 처리에서 시퀀스는 주로 단어나 문자의 연속을 나타낸다.\n",
    "<br>예를 들어, 문장은 단어들의 시퀀스이고, 단어는 문자들의 시퀀스입니다.\n",
    "<br>시퀀스 데이터는 순서가 중요하며, 이전 요소가 다음 요소에 영향을 미칠 수 있다.<br>\n",
    "\n",
    "* RNN(Recurrent Neural Network)<br> \n",
    "순차적 데이터를 처리하는 신경망으로, 이전 단계의 정보를 현재 단계로 전달하는 구조를 가짐\n",
    "* LSTM(Long Short-Term Memory)<br>\n",
    "RNN의 장기 의존성 문제를 해결하기 위해 개발된 모델로, 장기 기억을 유지할 수 있는 구조를 가짐\n",
    "* GRU(Gated Recurrent Unit)<br>\n",
    "LSTM을 간소화한 모델로, 더 적은 매개변수를 사용하면서도 비슷한 성능을 보임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01_01_02 Transformers 라이브러리란?\n",
    "* 허깅페이스에서 제공하는 최신 모델을 쉽게 사용할 수 있도록 도와주는 라이브러리이다.\n",
    "* 트랜스포머는 자연어 처리 분야에서 많이 사용되는 모델로, 다양한 언어 모델을 포함하고 있다.\n",
    "\n",
    "트랜스포머는 자연어 처리 분야의 주요 딥러닝 모델로, \"Attention is All You Need\" 논문에서 소개되었다.  \n",
    "Self-Attention 메커니즘을 사용하여 문맥 이해와 단어 간 관계 파악에 효과적이다.  \n",
    "기계 번역, 텍스트 생성, 질문 응답 등 다양한 작업에서 우수한 성능을 보인다.\n",
    "\n",
    "쉽게 생각하면 컴퓨터가 말하는 방법을 배우는 것과 비슷한 것으로 문장 속의 단어들이 어떤 관계를 가지고 있는지 파악하고 문장의 뜻을 이해하는데 기술이다\n",
    "\n",
    "* Transformers를 통해 사전학습된 최신 모델을 쉽게 다운로드하고 학습할 수 있는 API와 도구를 제공한다.\n",
    "\n",
    "**지원하는 기능**\n",
    "1) 자연어 처리 : 텍스트 분류, 엔티티 인식, 질문답변, 언어모델링, 요약, 번역, 객관식 텍스트 생성\n",
    "2) 컴퓨터 비전 : 이미지 분류, 물체감지 및 분할\n",
    "3) 오디오 : 음성인식 및 오디오 분류\n",
    "4) 멀티모달 : 테이블 질문 답변, 광학문자 인식, 스캔문서에서 정보추출, 비디오분류, 시각적 질문답변\n",
    "\n",
    "멀티모달이란 : 텍스트 이미지, 음성, 영상 등 다양한 양식으로 훈련해 다양한 결과물을 낼 수 있는 모델\n",
    "-> 즉, 여러가지 유형의 데이터를 동시에 다루는 기술\n",
    "\n",
    "https://huggingface.co/docs/transformers/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-02 사용방법\n",
    "**pipeline() 함수**\n",
    "* 다양한 task 를 위한 인터페이스를 제공하여, 복잡한 모델을 쉽게 사용 할 수 있게 해줍니다.\n",
    "* 특정 모델과 동작에 필요한 전처리 및 후처리 단계를 연결하여 텍스트를 직접 입력하고 이해하기 쉬운 답변을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pipline() 함수의 인자**\n",
    "\n",
    "1. 공통인자\n",
    "* task : 수행할 작업의 종류를 지정\n",
    "* model : 사용할 모델의 이름이나 경로를 지정\n",
    "* tokenizer : 사용할 토크나이저 지정( 모델과 함께 제공되는 토크나이저르 사용하는게 일반적이다. )\n",
    "* framework : 사용할 딥러닝 프레임워크 지정 (pt : 파이토치 , tf : 텐서플로우)\n",
    "* device : 실행할 장치 (cpu => -1 , gpu => 0),cude\n",
    "\n",
    "2. 작업별 인자\n",
    "* text-generation:\n",
    "    * max_length : 생성할 텍스트의 최대길이 지정\n",
    "    * num_return_squence : 생성할 텍스트의 개수 지정\n",
    "    * temperature : 무작위성을 조절하는 파라미터\n",
    "\n",
    "* question-answering:\n",
    "    * context : 질문에 대한 답을 찾을 문맥 제공\n",
    "    * question : 답을 찾고자 하는 질문\n",
    "\n",
    "* translation:\n",
    "    * src_lang : 원본 텍스트의 언어 지정\n",
    "    * tgt_lang : 번역할 목표 언어지정\n",
    "\n",
    "* summarization:\n",
    "    * min_length : 요약문에서 생성할 최소 단어 수 지정\n",
    "    * max_length : 요약문에서 생성할 최대 단어 수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers 패키지에서 pipeline 을 import\n",
    "from transformers import pipeline\n",
    "\n",
    "# 음성을 인식해서 텍스트로 출력할 수 있는 모델\n",
    "# STT (automatic-speech-recognition) : 음성인식\n",
    "transcriber = pipeline('automatic-speech-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(model=\"openai/whisper-large-v3-turbo\")\n",
    "transcriber('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoClass\n",
    "* 사전학습된 모델을 쉽게 사용할 수 있도록 도와주는 클래스\n",
    "* 수행하고하는 task 에 적합한 AutoModel 과 AutoTokenizaer 를 선택해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 토큰화만 진행\n",
    "# google-bert/bert-base-uncased 모델에 최적화된 토크나이저를 찾아내고\n",
    "# 다운로드하여 사용할 수 있게 해준다.\n",
    "tonizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squence = 'hello, my dog is cute'\n",
    "print(tonizer(squence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. AutoImageProcessor\n",
    "* 이미지 데이터를 모델에 처리할수 있는 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor , AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# google/vit-base-patch16-224 모델을 사용하는데 최적화된 이미지 프로세서(전처리기)를 가져온다.\n",
    "image_processor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# 이미지 다운로드\n",
    "url =\"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "\n",
    "image = Image.open(requests.get(url,stream=True).raw)\n",
    "\n",
    "# 이미지 전처리\n",
    "inputs = image_processor(images=image,return_tensors='pt')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 구성요소 | 목적 | 특성 | 데이터 타입 | 변형 과정 | 결과물 | 주요 사용 사례 |\n",
    "|---------|------|------|------------|-----------|--------|---------------|\n",
    "| 사전 훈련된 토크나이저 | 텍스트 데이터를 모델이 처리할 수 있는 형태로 변환 | 텍스트 토큰화, 인코딩, 어휘사전 관리 | 텍스트 | 토큰화, 인코딩 | 모델이 처리할 수 있는 텍스트 형태 | 자연어 이해 및 생성 작업 |\n",
    "| 사전 훈련된 이미지 프로세서 | 이미지 데이터를 모델이 처리할 수 있는 형태로 변환 | 이미지 크기 조정, 정규화, 텐서 변환 | 이미지 | 크기 조정, 정규화 | 모델이 처리할 수 있는 이미지 형태 | 이미지 분류, 객체 감지 |\n",
    "| 사전 훈련된 특성 추출기 | 데이터로부터 중요한 특성을 추출 | 다양한 데이터 타입 처리, 중요 특성 식별 | 다양한 데이터 | 중요 특성 추출 | 분석 및 모델 입력에 필요한 특성 | 데이터 분석, 모델 학습 |\n",
    "| 사전 훈련된 프로세서 | 다양한 데이터 타입의 전처리를 통합 관리 | 텍스트, 이미지 등 다양한 데이터 처리 | 텍스트, 이미지 등 | 통합 전처리 | 다양한 형태의 데이터 처리 | 멀티모달 입력을 가진 작업 |\n",
    "| 사전 훈련된 모델 | 특정 작업을 수행하는 데 바로 사용 가능 | 다양한 아키텍처, 사전 훈련된 가중치 | 텍스트, 이미지 | 가중치 튜닝 | 작업 수행(분류, 생성 등) | 자연어 및 이미지 처리 작업 |\n",
    "| AutoBackbone | 이미지 데이터를 효율적으로 처리할 수 있도록 모델 아키텍처 제공 | 사전 훈련된 가중치 사용, 다양한 모델 지원 가능성 제공 | 이미지 | 아키텍처 선택 및 튜닝 | 이미지 관련 작업에 적합한 모델 구조 | 이미지 분류, 객체 인식, 특성 추출 등 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
